{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet18_LLAMAS_Ladder_multiclass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "05upCbPRgp8d",
        "outputId": "5b4c49bb-834c-4765-cb8a-76b0d9868651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive/')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf3GupcpM806",
        "outputId": "1190ff7d-9227-45da-e79c-31ed68c9eaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Kompletan set za treniranje i labele\n",
        "#!unzip '/content/drive/My Drive/LLAMAS/train_all_labels_small_ids.zip'\n",
        "#!unzip '/content/drive/My Drive/LLAMAS/train_small_bil.zip'\n",
        "\n",
        "# Smanjeni set za treniranje i labele\n",
        "#!unzip '/content/drive/My Drive/LLAMAS/train_labels_small_ids.zip'\n",
        "!unzip '/content/drive/My Drive/LLAMAS/train_sort_small_bilinear.zip'\n",
        "# Set za validiranje i labele\n",
        "!unzip '/content/drive/My Drive/LLAMAS/valid_small_bilinear.zip'\n",
        "#!unzip '/content/drive/My Drive/LLAMAS/valid_labels_01.zip'\n",
        "# Set za testiranje\n",
        "#!unzip '/content/drive/My Drive/LLAMAS/test_small_bilinear.zip'\n",
        "#!unzip '/content/drive/My Drive/LLAMAS/test_small_ids.zip'\n",
        "# Smanjeni set za treniranje multi class\n",
        "!unzip '/content/drive/My Drive/LLAMAS/train_labels_small_ids_multi.zip'\n",
        "# Validiranje multiclass\n",
        "!unzip '/content/drive/My Drive/LLAMAS/valid_multi_class_ids.zip'\n",
        "\n",
        "#!unzip '/content/drive/My Drive/LLAMAS/train_slike.zip'\n",
        "#!unzip '/content/drive/My Drive/LLAMAS/train_labele.zip'\n",
        "!unzip '/content/drive/My Drive/LLAMAS/test_multi_lab.zip'\n",
        "!unzip '/content/drive/My Drive/LLAMAS/test_small_bilinear.zip'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Kompletan set za treniranje i labele\\n#!unzip '/content/drive/My Drive/LLAMAS/train_all_labels_small_ids.zip'\\n#!unzip '/content/drive/My Drive/LLAMAS/train_small_bil.zip'\\n\\n# Smanjeni set za treniranje i labele\\n#!unzip '/content/drive/My Drive/LLAMAS/train_labels_small_ids.zip'\\n!unzip '/content/drive/My Drive/LLAMAS/train_sort_small_bilinear.zip'\\n# Set za validiranje i labele\\n!unzip '/content/drive/My Drive/LLAMAS/valid_small_bilinear.zip'\\n#!unzip '/content/drive/My Drive/LLAMAS/valid_labels_01.zip'\\n# Set za testiranje\\n#!unzip '/content/drive/My Drive/LLAMAS/test_small_bilinear.zip'\\n#!unzip '/content/drive/My Drive/LLAMAS/test_small_ids.zip'\\n# Smanjeni set za treniranje multi class\\n!unzip '/content/drive/My Drive/LLAMAS/train_labels_small_ids_multi.zip'\\n# Validiranje multiclass\\n!unzip '/content/drive/My Drive/LLAMAS/valid_multi_class_ids.zip'\\n\\n#!unzip '/content/drive/My Drive/LLAMAS/train_slike.zip'\\n#!unzip '/content/drive/My Drive/LLAMAS/train_labele.zip'\\n!unzip '/content/drive/My Drive/LLAMAS/test_multi_lab.zip'\\n!unzip '/content/drive/My Drive/LLAMAS/test_small_bilinear.zip'\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR6Y-ec9DRQC",
        "outputId": "cc464f75-08e8-4ce2-b14e-ebb2b61a5f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "import glob\n",
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.model_zoo import load_url as loading\n",
        "from torch.autograd import Variable\n",
        "from sklearn import metrics as m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntry:\\n  from torch.hub import load_state_dict_from_url\\nexcept ImportError:\\n  from torch.utils.model_zoo import load_url as load_url'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dttOYZwZSbTi"
      },
      "source": [
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOUSywHjbyNg"
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1khfpapscEi3"
      },
      "source": [
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caJFwe16cEs9"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj0uIWZ5cEyY"
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsH8BZaUcE3w"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(\n",
        "                                 replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, \n",
        "                               padding=3,bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.conv2 = nn.Conv2d(512, 5, kernel_size=1, stride=1, bias=False)\n",
        "        self.upsample = nn.UpsamplingBilinear2d(size=(13, 40))\n",
        "        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "        self.upsample3 = nn.UpsamplingBilinear2d(size=(25, 80))\n",
        "        self.upsample4 = nn.UpsamplingBilinear2d(size=(50, 160))\n",
        "        self.conv3 = nn.Conv2d(256, 5, kernel_size=1, stride=1, bias=False)\n",
        "        self.conv4 = nn.Conv2d(128, 5, kernel_size=1, stride=1, bias=False)\n",
        "        self.conv5 = nn.Conv2d(64, 5, kernel_size=1, stride=1, bias=False)\n",
        "        self.conv6 = nn.Conv2d(5, 5, kernel_size=3, stride=1, bias=False)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x0 = self.conv1(x)\n",
        "        x0 = self.bn1(x0)\n",
        "        x0 = self.relu(x0)\n",
        "        x0 = self.maxpool(x0) #f0 izlaz\n",
        "\n",
        "        x1 = self.layer1(x0)  # f1 izlaz\n",
        "        x2 = self.layer2(x1)  #f2 izlaz\n",
        "        x3 = self.layer3(x2) # logiti na  predikciji /16 #f3 izlaz\n",
        "        x4 = self.layer4(x3)  #f4 izlaz\n",
        "        x5 = self.conv2(x4)\n",
        "        \n",
        "        x5 = self.upsample(x5)\n",
        "        x3 = self.conv3(x3)\n",
        "        x5 += x3\n",
        "        x5 = self.conv6(x5)\n",
        "        \n",
        "        x5 = self.upsample3(x5)\n",
        "        x2 = self.conv4(x2)\n",
        "        x5 += x2\n",
        "        x5 = self.conv6(x5)\n",
        "\n",
        "        x5 = self.upsample4(x5)\n",
        "        x1 = self.conv5(x1)\n",
        "        x5 += x1\n",
        "        x5 = self.conv6(x5)\n",
        "        x8 = torch.nn.functional.interpolate(x5, size=(288,960), mode='bilinear')\n",
        "        \n",
        "        return x8\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_47I2XMcE9A"
      },
      "source": [
        "def _load_pretrained(model, url, inchans=3):\n",
        "    state_dict = loading(url)\n",
        "    if inchans == 1:\n",
        "        conv1_weight = state_dict['conv1.weight']\n",
        "        state_dict['conv1.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n",
        "    elif inchans != 3:\n",
        "        assert False, \"Invalid number of inchans for pretrained weights\"\n",
        "    model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "def resnet18(pretrained=False, inchans=3):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "    if pretrained:\n",
        "        _load_pretrained(model, model_urls['resnet18'], inchans=inchans)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXe_F_nSI4jU"
      },
      "source": [
        "class LlamasDataset(Dataset):\n",
        "    \"\"\"LLAMAS dataset for lane tracking.\"\"\"\n",
        "    mean=[0.485, 0.456, 0.406]\n",
        "    std=[0.229, 0.224, 0.225]\n",
        "    def __init__(self,im_root, label_root, mode):\n",
        "        self.images = list(sorted(glob.glob(im_root+'*.png')))\n",
        "        self.im_root = im_root\n",
        "        self.labels = list(sorted(glob.glob(label_root+'*.png')))\n",
        "        self.label_root = label_root\n",
        "        self.normalize = transforms.Normalize([0.5],[0.5])\n",
        "        self.tenzoriraj = transforms.ToTensor()\n",
        "        self.resize_bil = transforms.Resize((288, 960), Image.BILINEAR)\n",
        "        self.resize_near = transforms.Resize((288, 960))\n",
        "        self.area = (0, 159, 638, 359)\n",
        "        self.mode = mode\n",
        "    \n",
        "    def transforms(self, image, label, mode):\n",
        "          image = image.crop(self.area)\n",
        "          image = self.tenzoriraj(image)\n",
        "          image = self.normalize(image)\n",
        "\n",
        "          label = label.crop(self.area)\n",
        "          label = self.resize_near(label)\n",
        "          label = np.array(label)\n",
        "          label_1d = torch.tensor(label)\n",
        "\n",
        "          if mode == \"test\":\n",
        "            h, w = label.shape\n",
        "            \n",
        "            prazna = np.zeros([5, w, h])\n",
        "\n",
        "            indeks0 = np.where(label[:,:] == 0)\n",
        "            indeks1 = np.where(label[:,:] == 1)\n",
        "            indeks2 = np.where(label[:,:] == 2)\n",
        "            indeks3 = np.where(label[:,:] == 3)\n",
        "            indeks4 = np.where(label[:,:] == 4)\n",
        "            \n",
        "            prazna[0, indeks0] = 1\n",
        "            prazna[1, indeks1] = 1\n",
        "            prazna[2, indeks2] = 1\n",
        "            prazna[3, indeks3] = 1\n",
        "            prazna[4, indeks4] = 1\n",
        "\n",
        "            label_5d = torch.tensor(prazna)\n",
        "            label_5d = label_5d.permute(0, 2, 1)\n",
        "            return image, label_1d, label_5d\n",
        "\n",
        "          return image, label_1d\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image = Image.open(self.images[item])\n",
        "        label= Image.open(self.labels[item])\n",
        "        return self.transforms(image, label,self.mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxZ8pFNrI4v9"
      },
      "source": [
        "train_root = 'train_sort_small_bilinear/'\n",
        "label_root = 'train_labels_small_ids_multi/'\n",
        "\n",
        "test_root = 'test_small_bilinear/'\n",
        "test_labels_root = 'test_multi_lab/'\n",
        "\n",
        "valid_root = 'valid_small/'\n",
        "valid_labels_root = 'valid_manji/'\n",
        "\n",
        "device = torch.device('cuda')\n",
        "epochs = 80\n",
        "batch_size = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs97b83sI-l9"
      },
      "source": [
        "dataset_train = LlamasDataset(im_root=train_root, label_root=label_root, mode='test')\n",
        "train_loader = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "dataset_test = LlamasDataset(im_root=test_root, label_root=test_labels_root, mode='test')\n",
        "test_loader = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "dataset_valid = LlamasDataset(im_root=valid_root, label_root=valid_labels_root, mode='test')\n",
        "valid_loader = DataLoader(dataset=dataset_valid, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUE_DbWFJ_2f"
      },
      "source": [
        "network = resnet18(pretrained=True, inchans=1)\n",
        "weights = torch.tensor([0.4, 1.0, 1.0, 1.0, 1.0]).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = optim.Adam(network.parameters())\n",
        "network.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TquUQ5IKAAp"
      },
      "source": [
        "def train(epoch):\n",
        "    network.train()\n",
        "    map_values = {0:0, 1:0, 2:0, 3:0, 4:0}\n",
        "    total = len(train_loader.dataset) / 12\n",
        "    ap = 0\n",
        "    for batch_idx, (data, target, target_5d) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        target = target.squeeze(1)\n",
        "        target = target.type(torch.cuda.LongTensor)\n",
        "        target_5d = target_5d.type(torch.cuda.LongTensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output= network(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        map(output, target_5d, 5, map_values)\n",
        "\n",
        "    ap += map_values[1]/total\n",
        "    ap += map_values[2]/total\n",
        "    ap += map_values[3]/total\n",
        "    ap += map_values[4]/total\n",
        "    ap /= 4\n",
        "    print('Train| Epoch {}| Avg. loss: {:.4f}| IoU: {:.4f})'.format(epoch, \n",
        "          loss.item(), ap))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovLXaBYy6845"
      },
      "source": [
        "\n",
        "def valid(epoch):\n",
        "    network.eval()\n",
        "    valid_loss = 0\n",
        "    ap = 0\n",
        "    values = {0:0, 1:0, 2:0, 3:0, 4:0}\n",
        "    total_valid = len(valid_loader.dataset) / 12\n",
        "    with torch.no_grad():\n",
        "        for data, target, target_5d in valid_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            target = target.squeeze(1)\n",
        "            target = target.type(torch.cuda.LongTensor)\n",
        "            target_5d = target_5d.type(torch.cuda.LongTensor)\n",
        "            output = network(data)\n",
        "            valid_loss += criterion(output, target).item()\n",
        "\n",
        "            map(output, target_5d, 5, values)\n",
        "\n",
        "    valid_loss /= total_valid\n",
        "    ap += values[1] / total_valid\n",
        "    ap += values[2] / total_valid\n",
        "    ap += values[3] / total_valid\n",
        "    ap += values[4] / total_valid \n",
        "    ap /= 4\n",
        "    print('Valid| Final| Avg. loss: {:.4f}| mAP: {:.4f})'.format(\n",
        "    valid_loss, ap))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Kffw5UKHnQ"
      },
      "source": [
        "def test():\n",
        "    network.eval()\n",
        "    test_loss = 0\n",
        "    ap = 0\n",
        "    values = {0:0, 1:0, 2:0, 3:0, 4:0}\n",
        "    total_test = len(test_loader.dataset) / 12\n",
        "    with torch.no_grad():\n",
        "        for data, target, target_5d in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            target = target.squeeze(1)\n",
        "            target = target.type(torch.cuda.LongTensor)\n",
        "            target_5d = target_5d.type(torch.cuda.LongTensor)\n",
        "            output = network(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "\n",
        "            map(output, target_5d, 5, values)\n",
        "\n",
        "    test_loss /= total_test\n",
        "    ap += values[1] / total_test\n",
        "    ap += values[2] / total_test\n",
        "    ap += values[3] / total_test\n",
        "    ap += values[4] / total_test \n",
        "    ap /= 4\n",
        "    print('Test| Final| Avg. loss: {:.4f}| mAP: {:.4f})'.format(\n",
        "    valid_loss, ap))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOZzhC2JZZi9"
      },
      "source": [
        "def map(predictions, labels, num_classes, map_value):\n",
        "    for i in range(num_classes):\n",
        "      prediction = predictions[:,i,:,:]\n",
        "      label = labels[:,i,:,:]\n",
        "      pr = prediction.cpu().numpy()\n",
        "      la = label.cpu().numpy()\n",
        "      lab = np.reshape(la, (la.shape[1]*la.shape[2]*la.shape[0],1))\n",
        "      pre = np.reshape(pr, (pr.shape[1]*pr.shape[2]*pr.shape[0],1))\n",
        "      app = m.average_precision_score(lab, pre, average=None)\n",
        "      if math.isnan(app):\n",
        "        app = 0\n",
        "      map_value[i] += app\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tysCgCN2KHsr"
      },
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    time0 = time.time()\n",
        "    train(epoch)\n",
        "    print(\"Running time for Epoch {}: {} min\\n\".format(epoch, (time.time() - time0)/60))\n",
        "    valid(epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMn1Fs43fwSM"
      },
      "source": [
        "valid(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5iKv1UqDaf4",
        "outputId": "0f335cc4-a07d-4bea-a8c3-886c5560e4c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "valid_loader2 = DataLoader(dataset=dataset_test, batch_size=1, shuffle=True, num_workers=2)\n",
        "\n",
        "dataiter = iter(valid_loader2)\n",
        "sljed = dataiter.next()\n",
        "slika, tar, n = sljed\n",
        "correct= 0\n",
        "with torch.no_grad():\n",
        "          data, target = slika.to(device), tar.to(device)\n",
        "          target = tar.squeeze(1)\n",
        "          target = target.type(torch.cuda.LongTensor)\n",
        "          output = network(data)\n",
        "          pred = output.data.max(1, keepdim=True)[1]\n",
        "        \n",
        "\n",
        "\n",
        "  \n",
        "izlaz = pred.squeeze(0)\n",
        "izlaz = izlaz.squeeze(0)\n",
        "izlaz = izlaz.cpu()\n",
        "izlaz = izlaz.numpy()\n",
        "izlaz = izlaz.astype(np.uint8)\n",
        "\n",
        "tar = target.squeeze(0)\n",
        "tar = tar.cpu()\n",
        "tar = tar.numpy()\n",
        "tar = tar.astype(np.uint8)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(tar)\n",
        "plt.title('Target')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(izlaz)\n",
        "plt.title('Predikcija mreže')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACTCAYAAAB1YlneAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAdQUlEQVR4nO3deXgcd53n8fe3qlvdui/Lsi3ZlmXLlo84iePYTgiDSZgh8MCEYWdYMswSeJgnsyz3HZhlhz2eBTIMEIZdGM6FGRbIwZKQh2NJOCZs4jtxYluyJduyJds6LMm6r6767h9VkuUrkm1J3er+vp6nn66uqu7+Van06V//6le/FlXFGGNMenGSXQBjjDEzz8LdGGPSkIW7McakIQt3Y4xJQxbuxhiThizcjTEmDVm4G2NMGrJwN2lJRPon3XwRGZr0+G1zVIbtItIyF+9lzMUiyS6AMbNBVfPGp0WkCfhrVX3qal5DRCKqmpjpshkzF6zmbjKKiGwRkedE5JyInBGRr4pI1qTlKiLvEZEGoCGc9/Fw3dMi8tfhOqvCZTER+YKInBSRNhH5uohki0gu8AtgyaRvDEuSstEmI1m4m0zjAR8CFgC3AXcB/+Gidd4EbAXWicjdwIeB1wCrgO0Xrfs5YDVwU7i8AvhPqjoAvA44rap54e30rGyRMZdh4W4yiqruVdUdqppQ1Sbgn4BXXbTaZ1W1S1WHgLcA31XVg6o6CHxmfCUREeB+4EPh+n3AfwfeOhfbYszLsTZ3k1FEZDXwRWAzkEPwP7D3otWaJ00vAfZcYVlZ+Bp7g5wP3gJwZ7DIxlwTq7mbTPM1oB6oUdUC4FMEgTzZ5KFSzwCVkx4vnTR9FhgC1qtqUXgrnHQy14ZcNUlj4W4yTT7QC/SLSC3w7inWfxh4p4isFZEc4NPjC1TVB74JfElEFgKISIWIvDZcpQ0oFZHCmd4IY6Zi4W4yzUeBvwT6CIL5xy+3sqr+AvgK8FugEdgRLhoJ7z8xPl9EeoGngDXhc+uBHwLHwt451lvGzBmxH+swZvpEZC1wAIhZH3iTyqzmbswUROTPwv7sxcDngZ9ZsJtUNyvhLiJ3i8hhEWkUkQdm4z2MmUN/A7QDRwn6yU/VTm9M0s14s4yIuMAR4I+BFmA3cK+qHprRNzLGGHNFs1Fz3wI0quoxVR0FfgTcMwvvY4wx5gpm4yKmCi680KOF4FLuK8qSmMbJnYWiGGNM+uqj+6yqll1uWdKuUBWR+wku3SZODlvlrmQVxRhj5qWn9NETV1o2G80yp7jwKr7KcN4FVPUbqrpZVTdHic1CMYwxJnPNRrjvBmpEZEU4lOpbgSdm4X2MMcZcwYw3y6hqQkTeC/yKYACl76jqwZl+H2OMMVc2K23uqvpz4Oez8drGGGOmZleoGmNMGrJwN8aYNGThbowxacjC3Rhj0pCFuzHGpCELd2OMSUMW7sYYk4Ys3I0xJg1ZuBszTgQcN5iMRHCLrvF3rR0XZ2Pt9N82mnVt72PMy7BwN5lHJLgBTjyOE48D4C4sw125HAD1FR0eufR506E+Ts8A7oJS3PKFL1+UWIyROzcikQiyeQOIBNMxG0zPXB8Ld5MxnNzcoEZeU43csh6JxVBV1PMB8Nra8RqOBSv7Hv7w8MRz3dISIiuW45ZddujsC6mSONEMiQQSjxGpWHLF2rmOjJD1qz1oIoHb1Q/i0PfmzbTefwtuQUGwkghOrv3egbk6SRvP3ZhZ47hEllfiNZ8CcXBLi0m0tk0s9o4cDWrh0/iJSYnFcAoK0MFB/N7T6NjotIvhnevBGR2j540bKawvRPfXvez6iWNNAOQ9spM8cfB8L9icnByGXrWO2M93n9/EePyCDx9jLmY1dzOvOfE4kcqKYDo/H7e0BNRHe/tQz0PHRieC3R8YQBOJ4IlTBLuTm4tbVIiOJYJgHxi4qmAf5w8Okv/wTvz9dUGtP2zTf1mqEAb7eLljv9hzfrkIw9tvQCJWNzNXZuFu5hUnJ2fi3snNRT0fDWuwfl8fXmcXqE7cXwu3oACpXIyOJYLmmYGB6yv0eDlGgjb8azqBOnlbVMn6v/vOf1BN4pYvDJpwHHf65whMWrJwN6llvGYrMhGCblHhJbVUf1Jt2jvbeX3vKRK0qVdXgQheby/ekaPXH+oX8Xp7cXJzOPPezVfVm+ayJtXsL5yvoIpbu5JI1bLrew8zr9n3OjN3xmuS47XQ8XZvxwX1g1CqXoZ3tAlU0cQYELRdj/MHB2e8WJHlSxlaVUb24bbzZbvGWv9U/L4+Kh89CYkE/iy8vtfREUwcOjKtmvv4B+i1NDmZ1GbhbmZPGN4SzULHRoO28WiExLEmJJqFW7mYxPETQbCHvMbj558/SwF7sUTTSaJNJ7m0kWOW3q+5BYBIdRX96xeSu6sJr6195t9oiv0nkQidf3ULw6VCTpuSfTZB9r8eCj5A52jfm9lj4W5mlJObiz80jFtWCiWFeHUNOIX5SCRCorllonlFx0aDYIc5CxInHsffWEPkZPsFvWeSRSMuJ/9Uce6spvZBh8SZ1rl9/0SCkv+1g0jFEvpvrmCwPMLpv93I0qdHGVgUpfDoIOw6OPGtyswvoinwRyuQEt0qdyW7GOYqOfE4/ugY4ghOUSHe2U7cNaugrQPvXE/Qj3xkZOoXmgPu2hpO3V1GtE8pf/JYSoQ7QKSygiPvX0ZRPZR+f/dlT5LOGREkEsUpyKN3ew0D5S6jhVBalyD7p7uSVy5zRU/po3tVdfPlllm4m6mJEFlWCY6DZkWR0TESx0/grloBZ7uCIA+bXqbbf3wuyeYN9NTkUby/C7+hKeXal1O23dtxkWgEPC+5Hzrmil4u3K1ZxlwisngRZEWDMI+4yFgCrzQft70HevuCLoJc2D4+EUwpFuwAuq+OwhcEL0UDKuVCfZzvoSNX6JVjUp6Fe4ZzcnJwCgsgHo5loopXnI/b3Qe+jza34Q0PQxNzdsJxxvne5HO2xmQEC/cM4hYUQHYcEYFYeCGNCDhOOB5KS9B/umkeB3k6EQEJL0W5Ur/2ecRdtQJvQT7OS0dxykoZqygh8tKxie6t1vQzsyzc0834aIexGBKPQTQruAc0FjS1MDpGoulkMktppsHZWMup1xQzXKqsfLgHf39dSjZ7TZdflMtQeRxZsJ6Tr4eigxGyVq6n4xal5IBQ/rNjnHtlFYUHu/HqGoIPtjT4UEsWO6GaBpycHHBdxHXwVwYnPp3GluBE2OioDTA1X4ngrltN/cfyKF3Qx8hvF7DkNz3o8weTXbLrIrEYTk4Ofv8AA2+8GRQGyxzG8gXxwI9AvEsZKRIqf9DIyPqlOKMezrMvWbfMi1hvmXTiuDjxGLguWluF1DcBwQUpqI/X25/e/wAiuLWr6LmhFPGUvCdfSJnulrPFXb+G+o/lcfvqoxzuWkj0X0oo+mXdBVfuzncSiYA4OLnZ9PzJWtwRn9ZtLiUHlES2MFQmLP11L8fvyWflj7pQV0gUZhPZXZfRlZfr6i0jIt8B3gC0q+qGcF4J8GOgCmgC3qKq3SIiwEPA64FB4B2qum8mNiITSSQSHPRhkDu9Q/hNLUh2HK+7B/YeQjPla6sI7uqVnLtpAZ0bhXiHUL57cKLnTjrzDh6m9vM17P2Lday56yiR93TRlLeO0m/vSJsP8fH2du/cKHkP7wARVj6Vg46O4dRUcfbWUvyoS2RQSBTGOfnaXMbyfWobCtFuTfsP+GsxZc1dRP4I6Ae+PyncHwS6VPVzIvIAUKyqnxCR1wPvIwj3rcBDqrp1qkJYzT24stMpKcbv7EKy40g0it/Xj+TlooND6PAI6nkZ1wYpsRiyZgXttxXTXwmxbqF89xDRl46lVc11OiQWY+hPbmRgocvC37deOFRDJnBcnOw4TkE+Z960AncEIsNKzwqHpU/3B+HfO4z/Yn3afOhN5bpq7qr6ryJSddHse4Dt4fT3gN8Bnwjnf1+DT4wdIlIkIotV9cy1FT09uUWFSHY2fm8fTkE+ZEXRwWFwg54RXmfX+ZVneGTCeUMEd9UK2u4sp28FSAIKjkHZoweCURuTXb4k0JER4j/bRRwycvvHh1/2BwYo+1owVIMTj1OclQWVixhaXYQz5gUnYjUj99AFrrW3TPmkwG4FysPpCqB50not4bxLwl1E7gfuB4iTc43FSH1Obi6SkxPUuCMRJBoNTnTmZiPDIxeOJ9KRvHKmDBHcoiKGtq6ifVOU0UKl6DCUPdOG39SCl6oX/Jik8IeHYXgYDvWSfSjZpUkt190VUlVVRK76O5CqfgP4BgTNMtdbjlTg5AcDZPmDg7gLSoNuiZ6HFuQhY4lwBMS02NRZo9s2cvKPchktUrJbYemv+5GDR/FmYahfY9LZtYZ723hzi4gsBsbHKz0FLJ20XmU4L/04Lk5uDngekp+HRKNobjZEXJxTrSROh19WVC/zvcVcTmRROd3Ls1EXFuxXCh7bi46NYh+Hxly9aw33J4D7gM+F949Pmv9eEfkRwQnVnrRobxfByc5GYjH8lRXgKXL4eNh9S/DaO+yCixmQaGun4LFuCgBNjJEK3XSNma+m0xXyhwQnTxeISAvwdwSh/rCIvAs4AbwlXP3nBD1lGgm6Qr5zFso8u8ZHwgOcZRX4Rbm4rd3o0FBQC3+hHgA/kYDJTQV2Auf6qabuIFrGzDPT6S1z7xUWXdJ3Mewl857rLdRcGu9H7qyqwo9HcPpH4FwvANraAU0tJDKwC6IxZn7LrLFlHDf4YYkVy9DcOKjidPYGv2fZ1IJ4Hn4iYQMYGWPmvfQMdxHckuKgt4rrIlnhCIh+MO6rdnTC6UQwEqL1wjDGpKF5H+4SieDk5QYPYrEgyB1B4zFwBOkfmvhBYmOMyRTzLtwnRkDMiiLZ2Wh+Dl5+HGdwDOnoItES9ry0nhbGmAyW0uHuxOPB8LWFBcE45IAW5aMRBznXT6L5dLCi72E/tGOMMeelTLhLNGhOcfJy8VcsQR3BOduH9g2gvo/f1R1c7XkqCHQLc2OMubKUCXenqDBoIxdB6o5DIkFidNSaV4wx5hqkTLh7HTZqljHGzBQn2QUwxhgz8yzcjTEmDVm4G2NMGrJwN8aYNGThbowxacjC3Rhj0lDKdIU0xqQ2iWbhlpedn+F5JFrb7FqUFGXhboyZFndJOcffvpTsLWfJjiY4N5jNgm8tJfaLPRbwKciaZYwx05I40czyL+5n+NkFLMrtZdPiZkbe10XvvVtxCwqSXTxzEQt3Y8y0+QMDLPvqSxz/5xp2nqyipqiDinc3cuTT64msWA6Om+wimpCFuzHmqvh9fSz45g5WfmaIZ15aQ05klG2vqOPMQ3F633qrBXyKsHA3xlw9Vby6Btb+Qzd7ntzAqYFCNpSdIfaOVlo/sBW3pjrZJcx4Fu7GmGvmHW5k6Wd3kvifi2juL2ZZfhc3vuUA9Z8uwl232mrxSWThboy5Pr5HzuN78L5azjP1NfjqcEdNIyf/W5Sud2wJfqvBzDkLd2PM9fM9sh/fxdqPHmfPU2sZ9SNsWtzM0nc0cuJTm3E21ia7hBnHwt0YM2O8zi6qHzrMgSdqaThXRl50hFtee4iTf+cimzcEP51p5oSFuzFmRnmdXVT8/U5y/r6I+q5yHPG5ZUkz5/7LMCc+tgm3fGGyi5gRLNyNMTPP94j87gUKP5fHMy+uoXc0m7UlbWy8u56GLy1h7DW3JLuEaW/KcBeRpSLyWxE5JCIHReQD4fwSEfm1iDSE98XhfBGRr4hIo4i8KCKbZnsjjDEpyPdwnnme2o/Wc+KRlZweKCQiPndUH6X7fQOc/ZvbiFQsSXYp09Z0au4J4COqug7YBrxHRNYBDwBPq2oN8HT4GOB1QE14ux/42oyX2hgzb/h9fZR/cy/yQDH/78XVjPkuN5WfYu19ddR/ZBmRpZXWZXIWTBnuqnpGVfeF031AHVAB3AN8L1zte8Cbwul7gO9rYAdQJCKLZ7zkxph5Q0dG0N0vse7B9omAd8Tntm31NH6hJOgyGbFxDGfSVbW5i0gVcDOwEyhX1TPholagPJyuAJonPa0lnHfxa90vIntEZM8YI1dZbGPMfJQ41sS6z57hpUfWcXY4D0d8ti5rouRtzbT9+y1EKi+JCnONph3uIpIHPAZ8UFV7Jy9TVQWuasxPVf2Gqm5W1c1RYlfzVGPMPJY40czif9xF31eWUte5CF8dynN6Wf+Xhzj8YBmyeYPV4mfAtMJdRKIEwf4DVf1JOLttvLklvG8P558Clk56emU4zxhjANBEgpzH91D2CeG5nbX46hB1PG5fcYzOz4zS+u4t1if+Ok2nt4wA3wbqVPWLkxY9AdwXTt8HPD5p/tvDXjPbgJ5JzTfmMiSaRaS6Cnf1ygtukRXL7dJtk758D+/gYWofbOK5nbX0jQXf4DcsOEPlvzlOy/s34WyoBZEkF3R+Ep3iF1RE5A7gGeAlwA9nf4qg3f1hYBlwAniLqnaFHwZfBe4GBoF3quqel3uPAinRrXLX9WzH/OS4RCoW07O1gvZNDhp2GBAfcs4IC/cM4OyuQ8dGk1tOY2ZZZFE5PXdUMXRfN+sXtOKKMuRFOdRRzqIHs5AdB8D3kl3MlPOUPrpXVTdfbtmU4T4XMjHcnZwc+u++gbM3uIwW+iCAQrRfqPzNCFkvHMU715PsYhozp7ztm2j/4BAbylqJOEGY13eVM/T7MpZ+ux6vsyvJJUwtLxfudtZijjk5Oei6ak7fUcDAUh91fFCIDAiFDVD2zBkSx5qwOorJRO7v9lF5eiUvvnkt695wmLg7xvrSVsbe1MFzi2tZ+egw8ux++83WabBwn0tbbuD0bfnnQx2QhJB/XFj8+068Q0dI2EFrMpx35ChLv3yKht5NLP+3RynIGiLqeLxi2yGOrFlI/Kubif1ynzXTTMHCfbaJ4NauomdDCZ0bXMbyzzfBZLc5LH52CHfXIbwR6+tvzDh/eJhF39nH2bYbOfzWQW6tPIEryurido693+fM7VtY9a1TJJpOJruoKcvCfRa5RYW0/8U6eqvBi2lwplSD2vqSP3jk7TiG19Z+dRcIGJMh/OFhch/bSUHdap77j9XcsvwkWU6CmqIOqu7s4tmiNaz+bj6675A101yGnVCdBZFF5QzcvIzOG6IMLjpfU48MCXknYeGOc+iho9YLxphpilQto2N7BcX/rpkluUFHgzHf5cxgAecerqD8RwfxenuneJX0YydU54jEYjjLKznxZ+UMl/moe76mntUrVP5mEGfXIXwLdWOuSqLpJCU/aKVnZBNNbyrh5soWst0xluV1U/hXQzy/qZa1D3Xj1TUku6gpw2ruM0AiEZzq5Zx6XTlDizRsgiGorQ8Ky349TPTACbzuHjsJZMz1cFwi5WXUf7yKW7ccIdsdA8BT4Q8Nq1j1dQ93fyP+wECSCzo3rJ/7bBEhsmQx516xjI6bBC8+KdQHhIJjULbjLN7hYxbqxswgt3whRz5WzfKbTlORew5XFE+F9qF8Tv1yOct+eJJEc0uyiznrLNxnmgiRReV0v6qKzg1CIud8qIsPsU6H5Y+14TUcsxM9xswSJzeXsVvX0PPRftaWBle1AgwksmjoLKP0yzm4v3s+rf8HLdxnkFtawshNK2h5dRZetqIOE+Nhxs86LH52mOiuevzBwaSW05iMIILetpGGd2Zx69pj5EaC81meCke6F9K1v4xV/9KFd/Bwkgs6O+yE6kwQgVs3cGZLPn1VPuqGia6Qdc6h+IhP8XPNJE40TwzAY4yZZarIs/tZW1fM/g/XcuOrj5AbGcUVZW1JG972dp5ZVEPNt27C2XkATSSSXeI5Y+E+FRHcVSvoeGU5PavBi52PbmdEyD8Bi396jERbBwlrVzcmKbzubqo/9yJ1vTdScFcrKwvP4oriivLK2gba/2s+HT++lbJv786YgLdwvxIR3NUrab+jjN6V4MfCJhiCdvW8JodFf+iBAw0krGujMUnnDwxQ+Y/70N+s5NkPr+T26qMTAb8wu4/IvU3Ur97Mqv/dh+49mOzizjprc7+IRCK4ZQvovW05Zze6jBaEFyEB4gVNMGX7E+Q+dxTvbGdyC2uMuSx3/Rrq3lfI6prTlOf0Tpxs9VTY1byciq9nEdvXOO9HXrUTqtPkFhXS+cZ19FbL+WF4YeLq0oKjUPazRryOjqSW0xgzNbeggP47a+HdHVQVdF4Q8GeH8zj6h+Ws/IdD8zrg7YTqFJycHFhdxZlXFNFX7aPO+ZOl4gkL9yhF+9rQU6141gvGmHnB6+0l+4m9DHELz9+XzfqFrWQ5QXv7gng/ea8+wp6SWqofGcP9ffp1mczscHdcIksW0fa6ZZxbTTBcwHh/dU+IdQvlu0aI/eEg3vBwsktrjLlavkf2T3eRv3sJx+9aw2j+hT/ZVwiMlECOOKDp1SEiI8NdolnI+lV03lTIuVrwsvSCJph4h0P57hFiz9bhDw5a10Zj5rnEqdMUff90sosxpzIu3N3iYvq2r6Z1m4MfnRTqgDMm5B+HRY8cxuvswk+zr2nGmMyRMeHuFheTWLeclm05DC5SNHI+uMWHnFMOC/cNE91xyJpgjDHzXtqHu5Ofj7+2ipN35jNSoviR871gnDEh1iksfH6U+O6jeN3d1gRjjEkLaRvuTm4uuq6a1i359C9T/OiFXRvdEaGoHhb8nwN4vb32g9TGmLSSfuEugltURPuba+lZDX7WpLq4gpMIQr1sZxd+Y5P9dqkxJi2lVbi7pSX0bq+he7XLyAJ/YrgAAGdUyG4XyncOEtlTb+3qxpi0lh7hLoLefiPNt+cwuNgPzpBOprBwr5L/+D50ZMTa1Y0xaS8lhh8QkT4gPQdcvj4LgLPJLkQKsv1yKdsnl5fu+2W5qpZdbkGq1NwPX2l8hEwmIntsv1zK9sulbJ9cXibvF2fqVYwxxsw3Fu7GGJOGUiXcv5HsAqQo2y+XZ/vlUrZPLi9j90tKnFA1xhgzs1Kl5m6MMWYGWbgbY0waSnq4i8jdInJYRBpF5IFkl2euiMhSEfmtiBwSkYMi8oFwfomI/FpEGsL74nC+iMhXwv30oohsSu4WzC4RcUXkeRF5Mny8QkR2htv/YxHJCufHwseN4fKqZJZ7NolIkYg8KiL1IlInIrdl+vEiIh8K/38OiMgPRSRux0ogqeEuIi7wP4DXAeuAe0VkXTLLNIcSwEdUdR2wDXhPuO0PAE+rag3wdPgYgn1UE97uB74290WeUx8A6iY9/jzwJVVdBXQD7wrnvwvoDud/KVwvXT0E/FJVa4EbCfZPxh4vIlIBvB/YrKobABd4K3asBFQ1aTfgNuBXkx5/EvhkMsuUxH3xOPDHBFfqLg7nLSa4wAvgn4B7J60/sV663YBKgqC6E3iSYDzPs0Dk4uMG+BVwWzgdCdeTZG/DLOyTQuD4xduWyccLUAE0AyXh3/5J4LWZfqyM35LdLDP+xxnXEs7LKOHXw5uBnUC5qp4JF7UC5eF0Ju2rLwMfh4lhgEqBc6qaCB9P3vaJ/RIu7wnXTzcrgA7gu2Fz1bdEJJcMPl5U9RTwBeAkcIbgb78XO1aAFGhzz3Qikgc8BnxQVXsnL9OgipFRfVVF5A1Au6ruTXZZUkwE2AR8TVVvBgY43wQDZN7xEp5fuIfgg28JkAvcndRCpZBkh/spYOmkx5XhvIwgIlGCYP+Bqv4knN0mIovD5YuB9nB+puyrVwB/KiJNwI8ImmYeAopEZHwspMnbPrFfwuWFQOdcFniOtAAtqrozfPwoQdhn8vHyGuC4qnao6hjwE4LjJ9OPFSD54b4bqAnPbmcRnAx5IsllmhMiIsC3gTpV/eKkRU8A94XT9xG0xY/Pf3vYC2Ib0DPp63jaUNVPqmqlqlYRHA+/UdW3Ab8F/jxc7eL9Mr6//jxcP+1qr6raCjSLyJpw1l3AITL7eDkJbBORnPD/aXyfZPSxMiHZjf7A64EjwFHgb5Ndnjnc7jsIvkK/CLwQ3l5P0Ab4NNAAPAWUhOsLQc+io8BLBD0Ekr4ds7yPtgNPhtPVwC6gEXgEiIXz4+HjxnB5dbLLPYv74yZgT3jM/BQozvTjBfjPQD1wAPhnIGbHSnCz4QeMMSYNJbtZxhhjzCywcDfGmDRk4W6MMWnIwt0YY9KQhbsxxqQhC3djjElDFu7GGJOG/j+DHdU4NJLEIgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}